{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92252e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from computing_similarity_modified import *\n",
    "import pandas as pd\n",
    "import obonet\n",
    "import networkx as nx\n",
    "#####generate ontology file for bingo,below example generate file of biological process terms\n",
    "from scipy.stats import hypergeom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c82549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bingo(networks):\n",
    "    def __init__(self,time):\n",
    "        file_url=corresponding_time(time)\n",
    "        super().__init__(file_url[0],file_url[1])\n",
    "\n",
    "    def export(self):\n",
    "        ontology=self.ontology\n",
    "        with open('./ontology.txt','w') as f:\n",
    "            f.write('(curator=GO)(type=all)' + '\\n')\n",
    "\n",
    "            for x in ontology.nodes:\n",
    "                name = ontology.nodes[x]['name']\n",
    "                x1 = x.split(':')[1]\n",
    "                if x in ['GO:0008150', 'GO:0005575', 'GO:0003674']:\n",
    "                    f.write(x1 + '=' + name + '\\n')\n",
    "                else:\n",
    "                    name = name + ' [isa: '\n",
    "                    parents = ontology.nodes[x]['is_a']\n",
    "                    for parent in parents:\n",
    "                        parent_name = parent.split(':')[1]\n",
    "                        name = name + str(parent_name) + ' '\n",
    "                    name += ']'\n",
    "                f.write(x1 + ' = ' + name + '\\n')\n",
    "\n",
    "        annotation=self.annotation\n",
    "        df=nx.to_pandas_edgelist(annotation)\n",
    "        df['target']=df['target'].apply(lambda x:x.split(':')[1]).astype('str')\n",
    "        df['output'] = df['source'] + ' = ' + df['target']\n",
    "        output = df['output'].to_list()\n",
    "        with open('./annotation.txt', 'w') as f1:\n",
    "            f1.write('(species=Homo Sapien)(type=all)(curator=GO)' + '\\n')\n",
    "            for line in output:\n",
    "                f1.write(line + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc928883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdr(p_vals):\n",
    "    from scipy.stats import rankdata\n",
    "    ranked_p_values = rankdata(p_vals)\n",
    "\n",
    "    fdr1 = [x * len(p_vals) / y for x, y in zip(p_vals, ranked_p_values)]\n",
    "    fdr1 = [x if x <= 1 else 0 for x in fdr1]\n",
    "    return fdr1\n",
    "\n",
    "class enerich(networks):\n",
    "    def __init__(self,time):\n",
    "        file_url=corresponding_time(time)\n",
    "        super().__init__(file_url[0],file_url[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def enrichmentanalysis(self, inputgene):\n",
    "        ontology = self.ontology\n",
    "        annotation = self.annotation_genes\n",
    "        annotation = nx.to_pandas_edgelist(annotation)\n",
    "        associated = annotation.loc[annotation['source'].isin(inputgene)]\n",
    "        related_go = list(set(associated['target'].to_list()))\n",
    "        associated_go_list = []\n",
    "        M = len(set(annotation.source.to_list()))  # M\n",
    "        N = len(inputgene)  # N\n",
    "        df = pd.DataFrame(columns=['GO term', 'p_value','k','M','N','n'])\n",
    "        num = 0\n",
    "        for x in related_go:\n",
    "            ancestors = list(nx.descendants(ontology, x))\n",
    "            associated_go_list.extend(ancestors)\n",
    "            associated_go_list.append(x)\n",
    "            associated_go_list = list(set(associated_go_list))\n",
    "        for term in associated_go_list:\n",
    "\n",
    "            descendants = list(nx.ancestors(ontology, term))\n",
    "            descendants.append(term)\n",
    "            k = len(associated.loc[associated['target'].isin(descendants), 'source'].drop_duplicates())  # k\n",
    "            #k = len(set([x[0] for x in associated if x[1] in descendants]))\n",
    "            n = len(annotation.loc[annotation['target'].isin(descendants), 'source'].drop_duplicates())  # n\n",
    "            #n = len(set([x[0] for x in annotation.edges() if x[1] in descendants]))\n",
    "            P = hypergeom.sf(k - 1, M, n, N)\n",
    "            df.loc[num] = [term, P,k,M,N,n]\n",
    "            num += 1\n",
    "        df.sort_values(by='p_value',inplace=True)\n",
    "        df['adjusted']=fdr(df['p_value'])\n",
    "        return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
